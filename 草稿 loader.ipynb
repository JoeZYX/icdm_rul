{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\joezh\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\numpy\\core\\__init__.py:29: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\users\\joezh\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\numpy\\.libs\\libopenblas.IPBC74C7KURV7CB2PKT5Z5FNR3SIBV4J.gfortran-win_amd64.dll\n",
      "c:\\users\\joezh\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tsfresh.feature_selection.significance_tests import target_real_feature_real_test, target_real_feature_binary_test\n",
    "from sklearn import preprocessing\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "def identify_and_remove_unique_columns(Dataframe):\n",
    "    Dataframe = Dataframe.copy()\n",
    "    del Dataframe[\"engine_id\"]\n",
    "    del Dataframe[\"cycle\"]\n",
    "    \n",
    " \n",
    "    unique_counts = Dataframe.nunique()\n",
    "    record_single_unique = pd.DataFrame(unique_counts[unique_counts == 1]).reset_index().rename(columns = {'index': 'feature', 0: 'nunique'})\n",
    "    unique_to_drop = list(record_single_unique['feature'])\n",
    "    Dataframe = Dataframe.drop(columns = unique_to_drop)\n",
    "    \n",
    "\n",
    "    unique_counts = Dataframe.nunique()\n",
    "    record_single_unique = pd.DataFrame(unique_counts).reset_index().rename(columns = {'index': 'feature', 0: 'nunique'})\n",
    "    record_single_unique[\"type\"] = record_single_unique[\"nunique\"].apply(lambda x:\"real\" if x>2 else \"binary\")\n",
    "    for i in range(record_single_unique.shape[0]):\n",
    "        col = record_single_unique.loc[i,\"feature\"]\n",
    "        _type = record_single_unique.loc[i,\"type\"]\n",
    "        if _type == \"real\":\n",
    "            p_value = target_real_feature_real_test(Dataframe[col], Dataframe[\"RUL\"])\n",
    "        else:\n",
    "            le = preprocessing.LabelEncoder()\n",
    "            p_value = target_real_feature_binary_test(pd.Series(le.fit_transform(Dataframe[col])), Dataframe[\"RUL\"])\n",
    "        if p_value>0.05:\n",
    "            unique_to_drop.append(col)\n",
    "    \n",
    "    return  unique_to_drop\n",
    "\n",
    "\n",
    "\n",
    "def Cmapss_train_vali_batch_generator(training_data, sequence_length=15):\n",
    "    \"\"\"\n",
    "    data generate for turbofan dataset\n",
    "    Generator function for creating random batches of training-data\n",
    "    \"\"\"\n",
    "    \n",
    "    engine_ids = list(training_data[\"engine_id\"].unique())\n",
    "    #print(engine_ids)\n",
    "    temp = training_data.copy()\n",
    "    for id_ in engine_ids:\n",
    "        indexes = temp[temp[\"engine_id\"] == id_].index\n",
    "        traj_data = temp.loc[indexes]\n",
    "        cutoff_cycle = max(traj_data['cycle']) - sequence_length  + 1\n",
    "        \n",
    "        if cutoff_cycle<=0:\n",
    "            drop_range = indexes\n",
    "            print(\"sequence_length + window_size is too large\")\n",
    "        else:\n",
    "            cutoff_cycle_index = traj_data['cycle'][traj_data['cycle'] == cutoff_cycle+1].index\n",
    "            drop_range = list(range(cutoff_cycle_index[0], indexes[-1] + 1))\n",
    "            \n",
    "        temp.drop(drop_range, inplace=True)\n",
    "    indexes = list(temp.index)\n",
    "    del temp\n",
    "    \n",
    "    feature_number = training_data.shape[1]-3\n",
    "\n",
    "    x_shape = (len(indexes), sequence_length, feature_number)\n",
    "    x_batch = np.zeros(shape=x_shape, dtype=np.float32)\n",
    "    y_shape = (len(indexes), sequence_length)\n",
    "    y_batch = np.zeros(shape=y_shape, dtype=np.float32)\n",
    "\n",
    "\n",
    "    for batch_index, index in enumerate(indexes):\n",
    "        y_batch[batch_index] = training_data.iloc[index:index+sequence_length,-1]\n",
    "        x_batch[batch_index] = training_data.iloc[index:index+sequence_length, 2:-1].values\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    return x_batch, y_batch   \n",
    "\n",
    "\n",
    "def Cmapss_test_batch_generator(test_data, sequence_length=5):\n",
    "\n",
    "    engine_ids = list(test_data[\"engine_id\"].unique())\n",
    "\n",
    "    feature_number = test_data.shape[1]-3 \n",
    "    \n",
    "    x_batch = []\n",
    "    y_batch = []\n",
    "    \n",
    "    for _id in set(test_data['engine_id']):\n",
    "        test_of_one_id =  test_data[test_data['engine_id'] == _id]\n",
    "        \n",
    "        if test_of_one_id.shape[0]>=sequence_length:\n",
    "            x_batch.append(test_of_one_id.iloc[-sequence_length:,2:-1].values)\n",
    "            y_batch.append(test_of_one_id.iloc[-sequence_length:,-1].values)\n",
    "        \n",
    "\n",
    "    return np.array(x_batch), np.array(y_batch)\n",
    "\t\n",
    "\t\n",
    "def cal_diff(df, sensor_name,diff_periods = 1):\n",
    "\n",
    "    sensor_diff = []\n",
    "\n",
    "    for _id in set(df['engine_id']):\n",
    "        trainFD001_of_one_id =  df[df['engine_id'] == _id]\n",
    "        s = pd.Series(trainFD001_of_one_id[sensor_name])\n",
    "\n",
    "        if len(s)>diff_periods:\n",
    "            sensor_diff_temp=s.diff(periods=diff_periods)\n",
    "\n",
    "            for i in range(diff_periods):\n",
    "                sensor_diff.append(s.iloc[i]-s.iloc[0])\n",
    "\n",
    "            for j in range (len(s)-diff_periods):\n",
    "                sensor_diff.append(sensor_diff_temp.iloc[diff_periods+j])\n",
    "        else:\n",
    "            for h in range(len(s)):\n",
    "                sensor_diff.append(s.iloc[h]-s.iloc[0])\n",
    "    return sensor_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cmapss_data_train_vali_loader(data_path, \n",
    "                                  Data_id, \n",
    "                                  flag  = \"train\",\n",
    "                                  sequence_length = 40,\n",
    "                                  MAXLIFE=120, \n",
    "                                  difference=False, \n",
    "                                  diff_periods = 1,\n",
    "                                  normalization=\"znorm\",\n",
    "                                  validation=0.1):\n",
    "\n",
    "\n",
    "    # --------------- read the train data, test data and labels for test ---------------\n",
    "\n",
    "    column_name = ['engine_id', 'cycle', 'setting1', 'setting2', 'setting3', 's1', 's2', 's3',\n",
    "                   's4', 's5', 's6', 's7', 's8', 's9', 's10', 's11', 's12', 's13', 's14',\n",
    "                   's15', 's16', 's17', 's18', 's19', 's20', 's21']\n",
    "\n",
    "    train_FD = pd.read_table(\"{}/train_{}.txt\".format(data_path,Data_id), header=None, delim_whitespace=True)\n",
    "    train_FD.columns = column_name\n",
    "\n",
    "\n",
    "    test_FD = pd.read_table(\"{}/test_{}.txt\".format(data_path,Data_id), header=None, delim_whitespace=True)\n",
    "    test_FD.columns = column_name\n",
    "\n",
    "    RUL_FD = pd.read_table(\"{}/RUL_{}.txt\".format(data_path,Data_id), header=None, delim_whitespace=True)\n",
    "\n",
    "    # ---------------- difference ------------------------\n",
    "    if difference:\n",
    "        diff_columns = train_FD.columns[2:]\n",
    "        for i in range(len(diff_columns)):\n",
    "            sensor_name_temp = diff_columns[i]\n",
    "            diff = cal_diff(train_FD,sensor_name=sensor_name_temp) \n",
    "            name = sensor_name_temp+'_diff'\n",
    "            train_FD[name] = diff\n",
    "        for i in range(len(diff_columns)):\n",
    "            sensor_name_temp = diff_columns[i]\n",
    "            diff = cal_diff(test_FD,sensor_name=sensor_name_temp) \n",
    "            name = sensor_name_temp+'_diff'\n",
    "            test_FD[name] = diff\n",
    "\n",
    "\n",
    "    # --------------- define the label for train and test ---------------\n",
    "    # piecewise linear RUL  for Training data\n",
    "    id='engine_id'\n",
    "    rul = [] \n",
    "    for _id in set(train_FD[id]):\n",
    "        trainFD_of_one_id =  train_FD[train_FD[id] == _id]\n",
    "        cycle_list = trainFD_of_one_id['cycle'].tolist()\n",
    "        max_cycle = max(cycle_list)\n",
    "\n",
    "        knee_point = max_cycle - MAXLIFE\n",
    "        kink_RUL = []\n",
    "        for i in range(0, len(cycle_list)):\n",
    "            # \n",
    "            if i < knee_point:\n",
    "                kink_RUL.append(MAXLIFE)\n",
    "            else:\n",
    "                tmp = max_cycle-i-1\n",
    "                kink_RUL.append(tmp)\n",
    "        rul.extend(kink_RUL)\n",
    "\n",
    "    train_FD[\"RUL\"] = rul\n",
    "\n",
    "    # piecewise linear RUL  for Test data\n",
    "    id='engine_id'\n",
    "    rul = []\n",
    "    for _id_test in set(test_FD[id]):\n",
    "        true_rul = int(RUL_FD.iloc[_id_test - 1])\n",
    "        testFD_of_one_id =  test_FD[test_FD[id] == _id_test]\n",
    "        cycle_list = testFD_of_one_id['cycle'].tolist()\n",
    "        max_cycle = max(cycle_list) + true_rul\n",
    "        knee_point = max_cycle - MAXLIFE\n",
    "        kink_RUL = []\n",
    "        for i in range(0, len(cycle_list)):\n",
    "            if i < knee_point:\n",
    "                kink_RUL.append(MAXLIFE)\n",
    "            else:\n",
    "                tmp = max_cycle-i-1\n",
    "                kink_RUL.append(tmp)    \n",
    "\n",
    "        rul.extend(kink_RUL)\n",
    "\n",
    "    test_FD[\"RUL\"] = rul\n",
    "\n",
    "    # --------------- acoording to the labels of training dataset, delete redundant input sensors ---------------\n",
    "\n",
    "    col_to_drop = identify_and_remove_unique_columns(train_FD)\n",
    "    print(col_to_drop)\n",
    "    train_FD = train_FD.drop(col_to_drop,axis = 1)\n",
    "    test_FD = test_FD.drop(col_to_drop,axis = 1)\n",
    "\n",
    "    # ---------------- Normalization --------------------------------\n",
    "\n",
    "    if normalization == \"znorm\":\n",
    "        mean = train_FD.iloc[:, 2:-1].mean()\n",
    "        std = train_FD.iloc[:, 2:-1].std()\n",
    "        std.replace(0, 1, inplace=True)\n",
    "\n",
    "\n",
    "        # training dataset\n",
    "        train_FD.iloc[:, 2:-1] = (train_FD.iloc[:, 2:-1] - mean) / std\n",
    "\n",
    "        # Testing dataset\n",
    "        test_FD.iloc[:, 2:-1] = (test_FD.iloc[:, 2:-1] - mean) / std\n",
    "\n",
    "    # ------------------- batch generator -------------------------------\n",
    "    \n",
    "    if flag == \"train\":    \n",
    "\n",
    "        data_x , data_y = Cmapss_train_vali_batch_generator(train_FD,sequence_length)\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        X_train, X_vali, y_train, y_vali = train_test_split(data_x, data_y, test_size=0.1, random_state=42)\n",
    "        return X_train, X_vali, y_train, y_vali\n",
    "        \n",
    "    else:\n",
    "        data_x, data_y = Cmapss_test_batch_generator(test_FD, sequence_length)\n",
    "    \n",
    "        return data_x, data_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CMAPSSData(Dataset):\n",
    "\n",
    "    def __init__(self, \n",
    "                 data_x,\n",
    "                 data_y ):\n",
    "        \n",
    "        self.data_x = data_x\n",
    "        self.data_y = data_y\n",
    "        self.data_channel = data_x.shape[2]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "\n",
    "\n",
    "        sample_x = self.data_x[index]\n",
    "        sample_y = self.data_y[index]\n",
    "\n",
    "\n",
    "        return sample_x,sample_y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96, 40, 15)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['setting3', 's1', 's5', 's10', 's16', 's18', 's19', 'setting1', 'setting2']\n"
     ]
    }
   ],
   "source": [
    "X_train, X_vali, y_train, y_vali = cmapss_data_train_vali_loader(\"CMAPSSData/\",\"FD001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['setting3', 's1', 's5', 's10', 's16', 's18', 's19', 'setting1', 'setting2']\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = cmapss_data_train_vali_loader(\"CMAPSSData/\",\"FD001\",\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_x, data_y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15057, 40, 15)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1674, 40, 15)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15057, 40)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1674, 40)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
